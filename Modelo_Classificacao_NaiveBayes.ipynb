{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modelo-Classificacao-NaiveBayes.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO5N6qQbjC5gdR11CO3Qlb6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jscienciadados/IA-Classificacao/blob/main/Modelo_Classificacao_NaiveBayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXkdGa5Ln5S6"
      },
      "source": [
        "# <font color='blue'>Classificador - Naive Bayes</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpzX1QWqoHpf"
      },
      "source": [
        "Construindo um classificador Naive Bayes com BernoulliNB em python.\n",
        "Não utilizei as função do sckit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpQMQu3tptVK"
      },
      "source": [
        "# Classificador Bernoulli"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZjWAc1_nwU6"
      },
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import logging\n",
        "import sys\n",
        "from time import time\n",
        "from math import *\n",
        "from matplotlib import pyplot as pl\n",
        "from matplotlib.backends.backend_pdf import PdfPages"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8UGmfU6oxvg"
      },
      "source": [
        "class MyBernClassifier():\n",
        " \n",
        "    def __init__(self, smooth = 1):\n",
        "        self._smooth = smooth\n",
        "        self._feat_prob = []\n",
        "        self._class_prob = []\n",
        "        self._Ncls = []\n",
        "        self._Nfeat = []\n",
        "\n",
        "    def train(self, X, y):\n",
        "        print (\"Treinando Bernoulli NB...\")\n",
        "        count_each_class = {}\n",
        "        feature_count = {}\n",
        "        alpha = self._smooth\n",
        "        temp = []\n",
        "        temp.append(np.unique(y))\n",
        "        self._Ncls.append(temp[0].size) # Número total de classes\n",
        "        self._Nfeat.append(X[0].size)  # Número total de features\n",
        "       \n",
        "        for i in range(y.size):\n",
        "            if y[i] in feature_count:\n",
        "                continue\n",
        "            else:\n",
        "                feature_count[y[i]] = [0 for w in range (X[i].size)]\n",
        "               \n",
        "\n",
        "        # Conta os atributos para cada classe através do treinamento ou\n",
        "        # conta a ocorrência de cada classe através do treinamento\n",
        "        for i in range (y.size):\n",
        "            if y[i] in count_each_class:\n",
        "                count_each_class[y[i]] +=1\n",
        "            else:\n",
        "                count_each_class[y[i]] = 1\n",
        "            for j in  range(X[i].size):\n",
        "                    feature_count[y[i]][j] += X[i][j]\n",
        "                   \n",
        "        # Calcula probabilidades de classe e atributos para cada classe      \n",
        "        for cls in feature_count:\n",
        "           \n",
        "            num = (self._smooth+count_each_class[cls])\n",
        "            din = (y.size+(self._Ncls[0]*self._smooth))\n",
        "            self._class_prob.append((num/float(din)))\n",
        "            ar = np.array([])\n",
        "            for j in  range(X[i].size):\n",
        "               \n",
        "                num = (feature_count[cls][j] + self._smooth)\n",
        "                din = (count_each_class[cls]+(2*self._smooth))\n",
        "                ar = np.append(ar,(num/float(din)))\n",
        "            self._feat_prob.append(ar)\n",
        "   \n",
        "\n",
        "    def predict(self, X):\n",
        "       \n",
        "        print (\"Fazendo Previsões com Bernoulli NB...\")\n",
        "       \n",
        "        Y_predict = np.array([])\n",
        "\n",
        "        for i in X:\n",
        "            neg_log_prob = 0\n",
        "            minimum_neg_log_prob = 999999999999999\n",
        "            category = 0  \n",
        "               \n",
        "            for cls in range(self._Ncls[0]):\n",
        "                neg_log_prob = -log(self._class_prob[cls])\n",
        "                for j in  range(self._Nfeat[0]):  \n",
        "                    if (i[j])==0:\n",
        "                        neg_log_prob -= log(1-self._feat_prob[cls][j])\n",
        "                    else:\n",
        "                        neg_log_prob -= log(self._feat_prob[cls][j])\n",
        "                       \n",
        "                if minimum_neg_log_prob>neg_log_prob:\n",
        "                    category=cls\n",
        "                    minimum_neg_log_prob=neg_log_prob\n",
        "           \n",
        "            Y_predict=np.append(Y_predict,category)\n",
        "         \n",
        "        return Y_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fljYNUU5qFax"
      },
      "source": [
        "# Classificador Multinomial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNUvGatLpJ8b"
      },
      "source": [
        "class MyMultinomialBayesClassifier():\n",
        "   \n",
        "    def __init__(self, smooth = 1):\n",
        "        self._smooth = smooth\n",
        "        self._feat_prob = []\n",
        "        self._class_prob = []\n",
        "        self._class_neg_prob = []\n",
        "        self._Ncls = []\n",
        "        self._Nfeat = []\n",
        "\n",
        "    def train(self, X, y):\n",
        "        print (\"Treinando Multinomial NB...\")\n",
        "       \n",
        "        count_each_class = {}\n",
        "        feature_count = {}\n",
        "     \n",
        "        for i in range(y.size):\n",
        "            if y[i] in feature_count:\n",
        "                continue\n",
        "            else:\n",
        "                feature_count[y[i]] = [0 for w in range (X[i].size)]\n",
        "               \n",
        "        for i in range (y.size):\n",
        "            if y[i] in count_each_class:\n",
        "                count_each_class[y[i]] +=1\n",
        "            else:\n",
        "                count_each_class[y[i]] = 1\n",
        "            for j in  range(X[i].size):\n",
        "                    feature_count[y[i]][j] += X[i][j]\n",
        "               \n",
        "        alpha = self._smooth\n",
        "        temp = []\n",
        "        temp.append(np.unique(y))\n",
        "        self._Ncls.append(temp[0].size)\n",
        "        self._Nfeat.append(X[0].size)  \n",
        "        self._class_prob.append(count_each_class)\n",
        "        self._feat_prob.append(feature_count)\n",
        "       \n",
        "       \n",
        "   \n",
        "    def predict(self, X):\n",
        "       \n",
        "        print (\"Fazendo Previsões com Multinomial NB...\")\n",
        "       \n",
        "        Y_predict = np.array([])\n",
        "       \n",
        "        # Calcula o total de classes para os dados de treino\n",
        "        total_train_count = 0\n",
        "        for key in self._class_prob[0]:\n",
        "            total_train_count += self._class_prob[0][key]\n",
        "       \n",
        "        for i in X:\n",
        "            neg_log_prob = 0\n",
        "            minimum_neg_log_prob=999999999999999\n",
        "            category = 0\n",
        "           \n",
        "            for cls in self._feat_prob[0]:\n",
        "                Ny = sum(self._feat_prob[0][cls])\n",
        "                neg_log_prob = -log((self._class_prob[0][cls]+1)/float(total_train_count+(self._Ncls[0]*self._smooth)))\n",
        "                for j in  range(self._Nfeat[0]):  \n",
        "                    if (i[j])==0:\n",
        "                        continue    \n",
        "                    for itere in range (i[j]):\n",
        "                        num = (self._smooth+self._feat_prob[0][cls][j])\n",
        "                        din = (Ny+(self._Nfeat[0]*self._smooth))\n",
        "                        neg_log_prob -= log(num/float(din))\n",
        "                       \n",
        "                if minimum_neg_log_prob>neg_log_prob:\n",
        "                    category=cls\n",
        "                    minimum_neg_log_prob=neg_log_prob\n",
        "           \n",
        "            Y_predict=np.append(Y_predict,category)\n",
        "         \n",
        "        return Y_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB4mGea4qUJk"
      },
      "source": [
        "# Define as classes que serão usadas no processo de classificação\n",
        "categories = [\n",
        "        'alt.atheism',\n",
        "        'talk.religion.misc',\n",
        "        'comp.graphics',\n",
        "        'sci.space',\n",
        "    ]\n",
        "remove = ('headers', 'footers', 'quotes')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5sivmVDqmoL"
      },
      "source": [
        "# Carrega os dados\n",
        "data_train = fetch_20newsgroups(subset = 'train', categories = categories, shuffle = True, random_state = 42, remove = remove)\n",
        "data_test = fetch_20newsgroups(subset = 'test', categories = categories, shuffle = True, random_state = 42, remove = remove)\n",
        "print('Dados Carregados!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdrFS1pxq7bg"
      },
      "source": [
        "# Treino e Teste\n",
        "y_train, y_test = data_train.target, data_test.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwJHNM8mrZur"
      },
      "source": [
        "print(\"Extraindo as features do dataset de treino usando o count vectorizer\")\n",
        "t0 = time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW0--Q1Rrhc4"
      },
      "source": [
        "# Binary = true for Bernoulli NB\n",
        "vectorizer = CountVectorizer(stop_words = 'english', binary = True)\n",
        "X_train = vectorizer.fit_transform(data_train.data).toarray()\n",
        "X_test = vectorizer.transform(data_test.data).toarray()\n",
        "feature_names = vectorizer.get_feature_names()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSRbpE19r1uA"
      },
      "source": [
        "# For Bernoulli NB, Binary = true, train for one default smooth value alpha = 1\n",
        "\n",
        "print ('-------------------------------------------------------------')\n",
        "print ('Tempo esperado para execução do modelo Bernoulli NB é 180 seg')\n",
        "ta = time()\n",
        "alpha = 1\n",
        "clf = MyBernClassifier(alpha)\n",
        "clf.train(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "tb = time()\n",
        "print (\"Para o modelo Bernoulli NB:  \" +'alpha = %f, accuracy = %f' %(alpha, np.mean((y_test - y_pred)==0)))\n",
        "print (\"Tempo total para treinar e prever com o modelo Bernoulli: \" + str(tb-ta))\n",
        "print ('-------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_vRXGkvtK_e"
      },
      "source": [
        "# Atenção:\n",
        "\n",
        "Usar uma GPU -> sem a mesma o treinamento pode levar horas....."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UIEs8f0sIyr"
      },
      "source": [
        "# Bernoulli Naive bayes: Alpha Vs accuracy\n",
        "acc = []\n",
        "alp = []\n",
        "\n",
        "for alpha in [float(j) / 100 for j in range(1, 101, 1)]:\n",
        "    print ('-----------------------------------------------------------------------------------------------------')\n",
        "    ta = time()\n",
        "    clf = MyBernClassifier(alpha)\n",
        "    clf.train(X_train,y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    acc.append(np.mean((y_test-y_pred)==0))\n",
        "    alp.append(alpha)\n",
        "    tb = time()\n",
        "    print (\"Tempo de treinamento: \" + str(tb-ta) + \" acurácia, alpha is: \" + str(np.mean((y_test-y_pred)==0)) +\",\"+str(alpha))\n",
        "\n",
        "# Plotting\n",
        "with PdfPages('Bernoulli.pdf') as pdf:\n",
        "    pl.plot(alp,acc,marker='.', linestyle = '-', color = 'r')\n",
        "    pl.ylabel('Acurácia',color='g')\n",
        "    pl.xlabel('Alpha',color='g')\n",
        "    pl.title('Plot Alpha Vs Acurácia para Bernoulli NB',color = 'r')\n",
        "    pdf.savefig()\n",
        "    pl.close()\n",
        "\n",
        "# Print\n",
        "print (\"Acurácia máxima do modelo Bernoulli NB is: \" + str(max(acc)))\n",
        "print (\"com valor correspondente para alpha de:       \" + str(alp[(acc.index(max(acc)))]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_yignJktZAT"
      },
      "source": [
        "# Binary = false para Multinomial NB\n",
        "\n",
        "print (\"Extraindo dados com Binary = False para Multinomial NB\")\n",
        "vectorizer = CountVectorizer(stop_words = 'english', binary = False)\n",
        "X_train = vectorizer.fit_transform(data_train.data).toarray()\n",
        "X_test = vectorizer.transform(data_test.data).toarray()\n",
        "feature_names = vectorizer.get_feature_names()\n",
        "\n",
        "print ('Tempo total esperado para execução do Multinomial NB é 90 seg')\n",
        "ta = time()\n",
        "alpha = 1\n",
        "clf1 = MyMultinomialBayesClassifier(alpha)\n",
        "clf1.train(X_train,y_train)\n",
        "y_pred = clf1.predict(X_test)\n",
        "\n",
        "print (\"Para modelo Multinomial NB:  \" +'alpha = %f accuracy = %f' %(alpha, np.mean((y_test-y_pred)==0)))\n",
        "tb = time()\n",
        "print (\"Tempo total para treinar e prever o modelo Multinomial: \" + str(tb-ta))\n",
        "print ('--------------------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpF7NovpU2Vv"
      },
      "source": [
        "# Multinomial Naive bayes: Alpha Vs accuracy\n",
        "acc = []\n",
        "alp = []\n",
        "\n",
        "for alpha in [float(j) / 100 for j in range(1, 101, 1)]:\n",
        "    print ('--------------------------------------------------------------------------------------')\n",
        "    ta = time()\n",
        "    clf1 = MyMultinomialBayesClassifier(alpha)\n",
        "    clf1.train(X_train,y_train)\n",
        "    y_pred1 = clf1.predict(X_test)\n",
        "    acc.append(np.mean((y_test-y_pred1)==0))\n",
        "    alp.append(alpha)\n",
        "    tb = time()\n",
        "    print (\"Tempo de Treinamento: \" + str(tb-ta) + \" acurácia, alpha é: \" + str(np.mean((y_test-y_pred1)==0)) +\",\"+str(alpha))\n",
        "    #print ('alpha=%f accuracy = %f' %(alpha, np.mean((y_test-y_pred1)==0)))\n",
        "\n",
        "# Plotting\n",
        "with PdfPages('multinomial.pdf') as pdf:\n",
        "    pl.plot(alp,acc,marker = '.', linestyle = '-', color = 'r')\n",
        "    pl.ylabel('Acurácia',color = 'g')\n",
        "    pl.xlabel('Alpha',color = 'g')\n",
        "    pl.title('Plot Alpha Vs Acurácia para Multinomial NB',color = 'r')\n",
        "    pdf.savefig()\n",
        "    pl.close()\n",
        "\n",
        "# Max Accuracy and Corresponding alpha.\n",
        "\n",
        "print (\"Acurácia máxima para o modelo Multinomial NB is: \" + str(max(acc)))\n",
        "print (\"com valor correspondente alpha de:       \" + str(alp[(acc.index(max(acc)))]))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}